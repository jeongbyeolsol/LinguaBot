{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8d5b48b0-1719-4bd1-82a6-4fe2c39c20f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is english grammar correction chatbot\n",
      "First model is simple verbs correction model, LinguaBot\n",
      "Second model is smart grammar correction model, Zrammar\n",
      "If you want change model, input model name\n",
      "Also if you want to quit, input 'quit' or 'exit'\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  hi\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinguaBot: More verbs are needed!\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  I am pizza\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinguaBot: Thanks! Your sentence looks okay to me.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  Zrammar\n",
      "You:  42 is most perfect number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zrammar: 43 is the most perfect number.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  Linguabot\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zrammar: Linguistics are not easy.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  hi run\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zrammar: Hi, I run a marathon.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  LinguaBot4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zrammar: Linguistics 4 - Linguistic - LinGuardias 4\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  LinguaBot\n",
      "You:  a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinguaBot: More verbs are needed!\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  hi\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinguaBot: More verbs are needed!\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  May I help you\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinguaBot: Thanks! Your sentence looks okay to me.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  fuck you!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinguaBot: More verbs are needed!\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  can\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinguaBot: More verbs are needed!\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  run\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinguaBot: Thanks! Your sentence looks okay to me.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  quit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinguaBot: Bye!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"pszemraj/grammar-synthesis-small\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"pszemraj/grammar-synthesis-small\")\n",
    "\n",
    "grammar_corrections = {\n",
    "    \"goed\": \"went\",\n",
    "    \"runned\": \"ran\",\n",
    "    \n",
    "    \"begined\" : \"began\",    \"bited\" : \"bit\",    \"breaked\" : \"broke\",    \"builded\" : \"built\",    \"burned\" : \"burnt\",    \"buyed\": \"bought\",\n",
    "    \n",
    "    \"catched\" : \"caught\",    \"comed\" : \"came\",    \"cuted\" : \"cut\",\n",
    "    \n",
    "    \"drawed\" : \"drew\",    \"drinked\" : \"drank\",    \"drived\" : \"drove\",\n",
    "\n",
    "    \"eated\": \"ate\",\n",
    "\n",
    "    \"falled\" : \"fell\",    \"feeded\" : \"fed\",    \"feeled\" : \"felt\",    \"fighted\" : \"fought\",    \"finded\" : \"found\",    \"flied\" : \"flew\",    \"forgeted\" : \"forgot\",\n",
    "\n",
    "    \"geted\" : \"got\",    \"gived\" : \"gave\",    \"growed\" : \"grew\",\n",
    "    \n",
    "    \"haved\" : \"had\",    \"heared\" : \"heard\",    \"hided\" : \"hid\",    \"hited\" : \"hit\",    \"holded\" : \"held\",\n",
    "\n",
    "    \"keeped\" : \"kept\",    \"knowed\" : \"knew\",\n",
    "    \n",
    "    \"leaded\" : \"led\",    \"learned\" : \"learnt\",    \"leaved\" : \"left\",    \"leted\" : \"let\",\n",
    "    \n",
    "    \"maked\" : \"maed\",    \"meaned\" : \"meant\",\n",
    "    \n",
    "    \"paied\" : \"paid\",    \"puted\" : \"put\",\n",
    "    \n",
    "    \"readed\" : \"read\",    \"rided\" : \"rode\",    \"rised\" : \"rose\",    \"runed\" : \"ran\",\n",
    "    \n",
    "    \"saied\" : \"said\",    \"selled\" : \"sold\",    \"singed\" : \"sang\",\n",
    "    \n",
    "    \"taked\" : \"took\",    \"theached\" : \"taught\",    \"telled\" : \"told\",    \"thinked\" : \"thought\",\n",
    "    \n",
    "    \"waked\" : \"woked\",    \"wined\" : \"win\",    \"writed\" : \"wrote\"\n",
    " }\n",
    "\n",
    "def extract_verbs_conjunction(sentence):\n",
    "    words = nltk.word_tokenize(sentence)\n",
    "    tagged = nltk.pos_tag(words)\n",
    "    verbs = [word for word, pos in tagged if pos.startswith('VB')]\n",
    "    conjs = [word for word, pos in tagged if pos in ('CC', 'IN')]\n",
    "    return verbs, conjs\n",
    "\n",
    "\n",
    "def check_verb_errors(sentence):\n",
    "    verbs, conj = extract_verbs_conjunction(sentence)\n",
    "    suggestions = []\n",
    "\n",
    "    for v in verbs:\n",
    "        lower_v = v.lower()\n",
    "        if lower_v in grammar_corrections:\n",
    "            suggestions.append((v, grammar_corrections[lower_v]))\n",
    "    \n",
    "    return suggestions\n",
    "\n",
    "\n",
    "def get_response(user_input):\n",
    "    corrections = check_verb_errors(user_input)\n",
    "    verbs, conjs = extract_verbs_conjunction(user_input)\n",
    "\n",
    "    if corrections:\n",
    "        messages = []\n",
    "        for wrong, correct in corrections:\n",
    "            messages.append(f\"Did you mean '{correct}' instead of '{wrong}'?\")\n",
    "            verbs.append(correct)\n",
    "        return \" \".join(messages)\n",
    "\n",
    "    if len(verbs) > (len(conjs) + 1):\n",
    "        return \"Too many verbs are exist!\"\n",
    "    elif len(verbs) < (len(conjs) + 1):\n",
    "        return \"More verbs are needed!\"\n",
    "        \n",
    "    # 다른 응답이 없다면 기본 메시지\n",
    "    return \"Thanks! Your sentence looks okay to me.\"\n",
    "\n",
    "\n",
    "def fix_grammar_with_transformer(sentence):\n",
    "    #input_text = \"Zrammar: \" + sentence\n",
    "    inputs = tokenizer([sentence], return_tensors=\"pt\", truncation=True)\n",
    "    outputs = model.generate(**inputs)\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    \n",
    "\n",
    "print(\"This is english grammar correction chatbot\")\n",
    "print(\"First model is simple verbs correction model, LinguaBot\")\n",
    "print(\"Second model is smart grammar correction model, Zrammar\")\n",
    "print(\"If you want change model, input model name\")\n",
    "print(\"Also if you want to quit, input 'quit' or 'exit'\\n\")\n",
    "model_choice  = 0\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"You: \")\n",
    "    \n",
    "    if user_input  == \"LinguaBot\":\n",
    "        model_choice  = 0\n",
    "        continue\n",
    "    elif user_input == \"Zrammar\":\n",
    "        model_choice  = 1\n",
    "        continue\n",
    "        \n",
    "    if user_input.lower() in ['exit', 'quit']:\n",
    "        print(\"LinguaBot: Bye!\")\n",
    "        break\n",
    "\n",
    "    if model_choice  == 0:\n",
    "        response = get_response(user_input)\n",
    "        print(\"LinguaBot:\", response)\n",
    "    elif model_choice  == 1:\n",
    "        response = fix_grammar_with_transformer(user_input)\n",
    "        print(\"Zrammar: \", end='')\n",
    "        print(response)\n",
    "    else:\n",
    "        print(\"oh my god. Error.\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
